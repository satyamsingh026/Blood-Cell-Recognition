{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Code Flow\n",
    "\n",
    "    1 -> Main method is called, main()\n",
    "    2 -> Inside main method, data object are initialised. Head to Data Constructor(Data.py) to know more(Just Constructor)\n",
    "    3 -> A flag is used to test or train\n",
    "    4 -> In Training, A checkpoint is created to save the progress of the model\n",
    "    5 -> Then the model is defined using height, width of image of dimension height * weight * 3, 3 -> RGB\n",
    "    6 -> Note we are using 20_4 model so just head to this model\n",
    "    7 -> First Feature learning is done using consecutive steps of Conv2d, Batch Normalization and Dropout\n",
    "    8 -> After Feature Learning Classification is done and layers are added like input, hidden and output\n",
    "    9 -> Then the Loss Function is Defined RMSprop and cross entropy\n",
    "   10 -> Now the model is trained using fit_generator method, batch by batch\n",
    "   11 -> In testing all the results are evaluated using evaluate_generator method, gives out a measure of performance (accuracy)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "my_random_seed = 1337\n",
    "np.random.seed(my_random_seed)\n",
    "tf.random.set_seed(my_random_seed)\n",
    "# tf.set_random_seed(my_random_seed)    \n",
    "\n",
    "# Intentsionally added step to avoid tensorflow Error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Adadelta, Adagrad, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "from data import Data\n",
    "\n",
    "# this_path = os.path.dirname(os.path.abspath(__file__))\n",
    "this_path = os.path.abspath('')\n",
    "\n",
    "\n",
    "def get_model(out_ht, out_wd, model_id):\n",
    "    inputs = Input(shape=(out_ht, out_wd, 3))\n",
    "    # Input is used to instantiate a Keras tensor. A Keras tensor is a tensor object from the underlying \n",
    "    # backend (TensorFlow in out case), which we augment with certain attributes that allow us to build a \n",
    "    # Keras model just by knowing the inputs and outputs of the model.\n",
    "    # shape => height/2 , width/2, 3 Here 3 -> RGB\n",
    "\n",
    "    # Note -> Since we are using 20_4 model for use, directly head to case where model_id = 20_4, line_no: 221\n",
    "\n",
    "    if model_id == '0':\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '1':\n",
    "        # Ran for 100 epochs: Shows overfitting. best validation accuracy: 78%\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '2_0':\n",
    "        # L2 regularization\n",
    "        # It does slow down the overfitting but validation accuracy gets stuck at ~60%\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l2())(inputs)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l2())(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu', kernel_regularizer=regularizers.l2())(x)\n",
    "        x = Dense(8, activation='relu', kernel_regularizer=regularizers.l2())(x)\n",
    "        x = Dense(4, activation='softmax', kernel_regularizer=regularizers.l2())(x)\n",
    "    elif model_id == '2_1':\n",
    "        # L1 regularization\n",
    "        # Accuracy of training and validation got stuck at 25%\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l1())(inputs)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l1())(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu', kernel_regularizer=regularizers.l1())(x)\n",
    "        x = Dense(8, activation='relu', kernel_regularizer=regularizers.l1())(x)\n",
    "        x = Dense(4, activation='softmax', kernel_regularizer=regularizers.l1())(x)\n",
    "    elif model_id == '3_0':\n",
    "        # Have dropout\n",
    "        # No overfitting. training loss was still decreasing. train acc: 70%, val_acc: 75%\n",
    "        # Need more epochs\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '3_1':\n",
    "        # Batch normalization\n",
    "        # Could not prevent from overfitting. Train acc: 93% val acc 70%\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(8)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '3_2':\n",
    "        # Batch normalization + Dropout\n",
    "        # Faster convergence. Has overvitting. train acc 82% val acc 66%\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same')(inputs)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '10_0':\n",
    "        # 3_0 with more epochs\n",
    "        # No overfitting. train acc: 70%, val_acc: 75%\n",
    "        # It gets hard to get more gains beyond it\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        # x = Dense(8, activation='relu')(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '20_0':\n",
    "        # Reducing the stride on conv layers\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '20_1':\n",
    "        # 20_0 with dropout\n",
    "        # Achieves 88% val accuracy in ~100 epochs\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '20_2':\n",
    "        # Increase model complexity with Dropout\n",
    "        # 88% val_acc in 80 epochs\n",
    "        # 95% val_acc in 200 epochs\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '20_3':\n",
    "        # Reduce the kernel size from 5 to 3\n",
    "        # val acc is lower than with kernel 5\n",
    "        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    # --------------------------------------\n",
    "    #           Just Focus Here\n",
    "    # --------------------------------------\n",
    "    elif model_id == '20_4':\n",
    "        # 20_2 with BatchNorm for faster convergence\n",
    "        # Gives 97% accuracy. Model saved as model_20_4_e1000.h5\n",
    "\n",
    "        # In Conv2d -> 2D Convolution Layer, This layer creates a convolution kernel that is \n",
    "        # convolved with the layer input to produce a tensor of outputs\n",
    "        # 1st Argument, Filters -> The number of output channels  i.e. 16\n",
    "        # 2nd Argument, Kernel Size -> 5, always keep it odd for better performance\n",
    "        # 3rd Argument, Strides -> (2, 2), Look into doc for better understanding\n",
    "        # 4th Argument, Padding -> Same, Look into doc for better understanding\n",
    "        # 5th Argument, Activation -> Relu activation function, Rectified Linear Unit\n",
    "\n",
    "        # Batch normalization layer -> Normalize the activations of the previous layer at each batch\n",
    "        # applies a transformation that maintains the mean activation close to 0 and \n",
    "        # the activation standard deviation close to 1. Detailed explaination in Google Doc\n",
    "\n",
    "        # Dropout is a technique used to prevent a model from overfitting.\n",
    "\n",
    "        # --------------------- Feature Learning Starts ---------------------------\n",
    "        # Input Layer\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        \n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        # I Think this is by mistake written twice by the author repeated twice!\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        # --------------------- Feature Learning Ends ---------------------------\n",
    "        # --------------------- Classification Starts ---------------------------\n",
    "\n",
    "        # Pooling \n",
    "        x = Flatten()(x)\n",
    "\n",
    "        # In our neural network, we are using 3 Hidden layers of 32, 16 and 8 dimension.\n",
    "        # The Dense is used to specify the fully connected layer. \n",
    "        # The arguments of Dense are output dimension which are 32 \n",
    "        \n",
    "        # First Hidden Layer\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        # Second Hidden Layer\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        # Third Hidden Layer\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        # Output Layer\n",
    "        # The output Layer for the case of multiclass classification takes softmax as activation function.\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "        # --------------------- Classification Ends ---------------------------\n",
    "\n",
    "    elif model_id == '100_0':\n",
    "        # A low capacity model\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '100_1':\n",
    "        # A low capacity model with dropout to show that capacity isn't enough\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '100_2':\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '100_3':\n",
    "        # 100_2 with Dropout\n",
    "        pass  # Same as 20_2\n",
    "    elif model_id == '100_4':\n",
    "        # 100_3 with BatchNormaliation\n",
    "        # 20_2 with BatchNorm for faster convergence\n",
    "        # Gives 97% accuracy. Model saved as model_20_4_e1000.h5\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id in ('100_5_0', '100_5_1', '100_5_2'):\n",
    "        # Effect of dropout amount\n",
    "        if model_id == '100_5_0':\n",
    "            dropout = 0.1\n",
    "        elif model_id == '100_5_1':\n",
    "            dropout = 0.2\n",
    "        elif model_id == '100_5_2':\n",
    "            dropout = 0.3\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id in ('100_6_0', '100_6_1', '100_6_2', '100_6_3'):\n",
    "        dropout = 0.2\n",
    "        # Effect of optimizers\n",
    "        if model_id == '100_6_0':\n",
    "            opt = Adam()\n",
    "        elif model_id == '100_6_1':\n",
    "            opt = Adadelta()\n",
    "        elif model_id == '100_6_2':\n",
    "            opt = Adagrad()\n",
    "        elif model_id == '100_6_3':\n",
    "            opt = RMSprop()\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "        outputs = x\n",
    "        m = Model(inputs=inputs, outputs=outputs)\n",
    "        print(m.summary())\n",
    "        m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return m\n",
    "    elif model_id in ('100_7_0', '100_7_1', '100_7_2'):\n",
    "        # Effect of activation function\n",
    "        dropout = 0.2\n",
    "        if model_id == '100_7_0':\n",
    "            act_fn = 'sigmoid'\n",
    "        elif model_id == '100_7_1':\n",
    "            act_fn = 'tanh'\n",
    "        elif model_id == '100_7_2':\n",
    "            act_fn = 'relu'\n",
    "        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(16, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(8, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id in ('100_8_0', '100_8_1'):\n",
    "        # Effect of Conv filter size\n",
    "        dropout = 0.2\n",
    "        act_fn = 'relu'\n",
    "        if model_id == '100_8_0':\n",
    "            filter_size = 3  # 3x3\n",
    "        elif model_id == '100_8_1':\n",
    "            filter_size = 5  # 5x5\n",
    "        x = Conv2D(16, filter_size, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(8, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(16, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(8, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "    elif model_id == '100_9_0':\n",
    "        # This could be the best model based on hyperparameters experimentation\n",
    "        # Nope: overfits slightly faster than validation loss\n",
    "        dropout = 0.1\n",
    "        act_fn = 'tanh'\n",
    "        filter_size = 5\n",
    "        opt = Adam()\n",
    "        x = Conv2D(16, filter_size, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(8, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(32, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(16, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(8, activation=act_fn)(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "        outputs = x\n",
    "        m = Model(inputs=inputs, outputs=outputs)\n",
    "        print(m.summary())\n",
    "        m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return m\n",
    "\n",
    "    outputs = x\n",
    "    m = Model(inputs=inputs, outputs=outputs)\n",
    "    print(m.summary())\n",
    "\n",
    "    # RMS Prop is an optimizer (Root Mean Square).\n",
    "    # Optimizers are algorithms or methods used to change the attributes \n",
    "    # of your neural network such as weights and learning rate in order to reduce the losses\n",
    "    opt = RMSprop()\n",
    "    # Categorical_crossentropy -> specifies that we have multiple classes\n",
    "    # Metrics -> used to specify the way we want to judge the performance of our neural network, via accuracy in out case\n",
    "    m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 128\n",
    "    # epochs = 1000\n",
    "    epochs = 10\n",
    "    # model_list = ['100_4']\n",
    "    model_list = ['20_4']\n",
    "    create_stat_image = False\n",
    "\n",
    "    resource_dir = os.path.join(this_path, 'resources')\n",
    "    os.makedirs(resource_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        data = Data(batch_size)\n",
    "    except Data.DataInitError as e:\n",
    "        print('Failed to initialize Data instance.\\n{:s}'.format(str(e)))\n",
    "        return\n",
    "\n",
    "    trainFlag = True\n",
    "\n",
    "    # if 0:  # Training\n",
    "    if trainFlag == True:\n",
    "\n",
    "        for model_id in model_list:  # Training\n",
    "            # model_path -> Output File for Training\n",
    "            model_path = os.path.join(resource_dir, model_id + '_model.h5')\n",
    "\n",
    "            # Save The Check point of the Model, It is an approach where a snapshot of the state of the \n",
    "            # system is taken in case of system failure\n",
    "            cb_save = ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "            m = get_model(data.out_ht, data.out_wd, model_id)\n",
    "\n",
    "            # ----------------------- Training the Model ---------------------\n",
    "\n",
    "            # fit_generator -> Trains the model on data generated batch-by-batch by a Python generator\n",
    "            # 1st argument -> generator, Training for now since we are training\n",
    "            # 2nd argument -> steps_per_epoch, It should typically be equal to ceil(num_samples / batch_size)\n",
    "            # 3rd argument -> validation_data\n",
    "            # 4th argument -> validation_steps, No of steps to yield from validation data before stopping at the end of every epoch\n",
    "            # 5th argument -> callbacks, Passing current saved weight\n",
    "\n",
    "            # print('############### Training Model ID: {:s} #####################'.format(model_id))\n",
    "            m.fit_generator(data.get_batch('TRAIN'),\n",
    "                            steps_per_epoch=data.steps_per_epoch,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=data.get_batch('VALIDATION'),\n",
    "                            validation_steps=data.validation_steps,\n",
    "                            shuffle=False,\n",
    "                            callbacks=[cb_save])\n",
    "\n",
    "    # if 1:  # Testing\n",
    "    if trainFlag == False:\n",
    "        # model_path = os.path.join(resource_dir, '20_2_model_e1000.h5')\n",
    "        # model_path = os.path.join(resource_dir, 'model_20_4_e1000.h5')\n",
    "\n",
    "        print(\"Inside Testing ^_^\")\n",
    "\n",
    "        # ----------------------- Testing the Model ----------------------\n",
    "\n",
    "        model_path = os.path.join(resource_dir, '20_4_model.h5')\n",
    "        m = load_model(model_path)\n",
    "\n",
    "        # evaluate_generator ->  uses both your test input and output. \n",
    "        # It first predicts output using training input and then evaluates performance by comparing it \n",
    "        # against your test output. So it gives out a measure of performance, i.e. accuracy in your case\n",
    "\n",
    "        eval_out = m.evaluate_generator(data.get_batch('TRAIN'),\n",
    "                                        steps=data.test_steps)\n",
    "        print('Train error: ', eval_out)\n",
    "\n",
    "        eval_out = m.evaluate_generator(data.get_batch('VALIDATION'),\n",
    "                                        steps=data.test_steps)\n",
    "        print('Validation error: ', eval_out)\n",
    "\n",
    "        eval_out = m.evaluate_generator(data.get_batch('TEST'),\n",
    "                                        steps=data.test_steps)\n",
    "        print('Test error: ', eval_out)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
