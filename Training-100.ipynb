{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training-100.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"p432FMB5Wdm5","colab_type":"code","outputId":"c4ca71a8-1a8a-45b0-d118-6f3e5af1d9b5","executionInfo":{"status":"ok","timestamp":1576650005340,"user_tz":300,"elapsed":6150,"user":{"displayName":"ishpreet singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBOMYelIpWRDXKf5OHRCPHy4uvNYyEHD-uQofvOmw=s64","userId":"05057968350501293125"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from zipfile import ZipFile\n","file_name = 'blood-cells.zip'\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print(\"Done :)\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Done :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZ-Vvgi6YPZD","colab_type":"code","outputId":"c21068fb-857a-4e15-dfca-c4368aac652d","executionInfo":{"status":"ok","timestamp":1576650052855,"user_tz":300,"elapsed":858,"user":{"displayName":"ishpreet singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBOMYelIpWRDXKf5OHRCPHy4uvNYyEHD-uQofvOmw=s64","userId":"05057968350501293125"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd blood-cells/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/blood-cells\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lAhpFqM9YV4U","colab_type":"code","outputId":"714839de-9d89-45c1-ed35-6fa19ea8c369","executionInfo":{"status":"ok","timestamp":1576651864223,"user_tz":300,"elapsed":1794686,"user":{"displayName":"ishpreet singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBOMYelIpWRDXKf5OHRCPHy4uvNYyEHD-uQofvOmw=s64","userId":"05057968350501293125"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 main.py  "],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From main.py:10: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","Using TensorFlow backend.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 120, 160, 3)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 60, 80, 16)        1216      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 60, 80, 16)        64        \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 60, 80, 16)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 40, 8)         3208      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 30, 40, 8)         32        \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 30, 40, 8)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 20, 4)         804       \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 15, 20, 4)         16        \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 15, 20, 4)         16        \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 15, 20, 4)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 10, 4)          404       \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 8, 10, 4)          16        \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 8, 10, 4)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 320)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                10272     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 16)                528       \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 8)                 136       \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 8)                 0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 36        \n","=================================================================\n","Total params: 16,748\n","Trainable params: 16,676\n","Non-trainable params: 72\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","############### Training Model ID: 20_4 #####################\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/100\n","71/71 [==============================] - 22s 308ms/step - loss: 1.5495 - acc: 0.2642 - val_loss: 1.3809 - val_acc: 0.2588\n","Epoch 2/100\n","71/71 [==============================] - 17s 238ms/step - loss: 1.3406 - acc: 0.3124 - val_loss: 1.3573 - val_acc: 0.3545\n","Epoch 3/100\n","71/71 [==============================] - 18s 252ms/step - loss: 1.2152 - acc: 0.4010 - val_loss: 2.6674 - val_acc: 0.3037\n","Epoch 4/100\n","71/71 [==============================] - 18s 253ms/step - loss: 1.1517 - acc: 0.4217 - val_loss: 1.1183 - val_acc: 0.4443\n","Epoch 5/100\n","71/71 [==============================] - 18s 253ms/step - loss: 1.1119 - acc: 0.4332 - val_loss: 1.0180 - val_acc: 0.4463\n","Epoch 6/100\n","71/71 [==============================] - 18s 252ms/step - loss: 1.0721 - acc: 0.4581 - val_loss: 1.0318 - val_acc: 0.4883\n","Epoch 7/100\n","71/71 [==============================] - 18s 249ms/step - loss: 1.0367 - acc: 0.4716 - val_loss: 0.9905 - val_acc: 0.5195\n","Epoch 8/100\n","71/71 [==============================] - 18s 250ms/step - loss: 1.0006 - acc: 0.5013 - val_loss: 0.9645 - val_acc: 0.5654\n","Epoch 9/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.9535 - acc: 0.5501 - val_loss: 0.8877 - val_acc: 0.6406\n","Epoch 10/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.8654 - acc: 0.6147 - val_loss: 0.7338 - val_acc: 0.7031\n","Epoch 11/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.8048 - acc: 0.6414 - val_loss: 0.8180 - val_acc: 0.6875\n","Epoch 12/100\n","71/71 [==============================] - 18s 255ms/step - loss: 0.7445 - acc: 0.6728 - val_loss: 0.6858 - val_acc: 0.7207\n","Epoch 13/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.7125 - acc: 0.6865 - val_loss: 0.6869 - val_acc: 0.7373\n","Epoch 14/100\n","71/71 [==============================] - 18s 255ms/step - loss: 0.6852 - acc: 0.7074 - val_loss: 0.7721 - val_acc: 0.7227\n","Epoch 15/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.6666 - acc: 0.7181 - val_loss: 0.6073 - val_acc: 0.7578\n","Epoch 16/100\n","71/71 [==============================] - 18s 254ms/step - loss: 0.6392 - acc: 0.7296 - val_loss: 0.5857 - val_acc: 0.7529\n","Epoch 17/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.6369 - acc: 0.7305 - val_loss: 0.5780 - val_acc: 0.7715\n","Epoch 18/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.6011 - acc: 0.7524 - val_loss: 0.5105 - val_acc: 0.7969\n","Epoch 19/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.5798 - acc: 0.7649 - val_loss: 0.6610 - val_acc: 0.7637\n","Epoch 20/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.5652 - acc: 0.7634 - val_loss: 0.5037 - val_acc: 0.7979\n","Epoch 21/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.5752 - acc: 0.7597 - val_loss: 0.4378 - val_acc: 0.8145\n","Epoch 22/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.5331 - acc: 0.7826 - val_loss: 0.4239 - val_acc: 0.8379\n","Epoch 23/100\n","71/71 [==============================] - 18s 254ms/step - loss: 0.5307 - acc: 0.7863 - val_loss: 0.4204 - val_acc: 0.8389\n","Epoch 24/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.5169 - acc: 0.7920 - val_loss: 0.4368 - val_acc: 0.8174\n","Epoch 25/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.5104 - acc: 0.7918 - val_loss: 0.3904 - val_acc: 0.8330\n","Epoch 26/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.4915 - acc: 0.8044 - val_loss: 0.3834 - val_acc: 0.8496\n","Epoch 27/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.4958 - acc: 0.7964 - val_loss: 0.3791 - val_acc: 0.8545\n","Epoch 28/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.4711 - acc: 0.8082 - val_loss: 0.4354 - val_acc: 0.8193\n","Epoch 29/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.4676 - acc: 0.8160 - val_loss: 0.4349 - val_acc: 0.8350\n","Epoch 30/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.4574 - acc: 0.8179 - val_loss: 0.4683 - val_acc: 0.8418\n","Epoch 31/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.4578 - acc: 0.8199 - val_loss: 0.3921 - val_acc: 0.8506\n","Epoch 32/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.4530 - acc: 0.8199 - val_loss: 0.4115 - val_acc: 0.8672\n","Epoch 33/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.4407 - acc: 0.8245 - val_loss: 0.3555 - val_acc: 0.8584\n","Epoch 34/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.4315 - acc: 0.8245 - val_loss: 0.3017 - val_acc: 0.8809\n","Epoch 35/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.4255 - acc: 0.8353 - val_loss: 0.3729 - val_acc: 0.8369\n","Epoch 36/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.4211 - acc: 0.8368 - val_loss: 0.4189 - val_acc: 0.8428\n","Epoch 37/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.4237 - acc: 0.8355 - val_loss: 0.3518 - val_acc: 0.8779\n","Epoch 38/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.3956 - acc: 0.8396 - val_loss: 0.5560 - val_acc: 0.8281\n","Epoch 39/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.4004 - acc: 0.8402 - val_loss: 0.3466 - val_acc: 0.8682\n","Epoch 40/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.4098 - acc: 0.8370 - val_loss: 0.2960 - val_acc: 0.8877\n","Epoch 41/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3962 - acc: 0.8471 - val_loss: 0.3262 - val_acc: 0.8779\n","Epoch 42/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.3833 - acc: 0.8498 - val_loss: 0.3023 - val_acc: 0.8750\n","Epoch 43/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.3789 - acc: 0.8520 - val_loss: 0.2634 - val_acc: 0.8975\n","Epoch 44/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.3825 - acc: 0.8519 - val_loss: 0.2973 - val_acc: 0.8818\n","Epoch 45/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3766 - acc: 0.8534 - val_loss: 0.2749 - val_acc: 0.8818\n","Epoch 46/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3718 - acc: 0.8597 - val_loss: 0.3463 - val_acc: 0.8740\n","Epoch 47/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3666 - acc: 0.8581 - val_loss: 0.2997 - val_acc: 0.8701\n","Epoch 48/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3618 - acc: 0.8626 - val_loss: 0.2743 - val_acc: 0.8984\n","Epoch 49/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3621 - acc: 0.8588 - val_loss: 0.3241 - val_acc: 0.8838\n","Epoch 50/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3658 - acc: 0.8612 - val_loss: 0.4546 - val_acc: 0.8477\n","Epoch 51/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.3630 - acc: 0.8606 - val_loss: 0.3223 - val_acc: 0.8896\n","Epoch 52/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3520 - acc: 0.8648 - val_loss: 0.3111 - val_acc: 0.8828\n","Epoch 53/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3565 - acc: 0.8660 - val_loss: 0.2554 - val_acc: 0.9062\n","Epoch 54/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3377 - acc: 0.8716 - val_loss: 0.2495 - val_acc: 0.9033\n","Epoch 55/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3552 - acc: 0.8649 - val_loss: 0.2531 - val_acc: 0.8994\n","Epoch 56/100\n","71/71 [==============================] - 18s 253ms/step - loss: 0.3370 - acc: 0.8678 - val_loss: 0.2468 - val_acc: 0.9121\n","Epoch 57/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3532 - acc: 0.8702 - val_loss: 0.2589 - val_acc: 0.9053\n","Epoch 58/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3434 - acc: 0.8689 - val_loss: 0.3495 - val_acc: 0.8838\n","Epoch 59/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3345 - acc: 0.8721 - val_loss: 0.2646 - val_acc: 0.9004\n","Epoch 60/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.3348 - acc: 0.8722 - val_loss: 0.2414 - val_acc: 0.9131\n","Epoch 61/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3337 - acc: 0.8716 - val_loss: 0.2683 - val_acc: 0.8926\n","Epoch 62/100\n","71/71 [==============================] - 18s 254ms/step - loss: 0.3158 - acc: 0.8776 - val_loss: 0.2394 - val_acc: 0.9102\n","Epoch 63/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3322 - acc: 0.8808 - val_loss: 0.4019 - val_acc: 0.8457\n","Epoch 64/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3260 - acc: 0.8789 - val_loss: 0.2715 - val_acc: 0.8965\n","Epoch 65/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3172 - acc: 0.8780 - val_loss: 0.3615 - val_acc: 0.8887\n","Epoch 66/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3172 - acc: 0.8796 - val_loss: 0.4084 - val_acc: 0.8760\n","Epoch 67/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3143 - acc: 0.8822 - val_loss: 0.2598 - val_acc: 0.9072\n","Epoch 68/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3067 - acc: 0.8863 - val_loss: 0.2668 - val_acc: 0.9141\n","Epoch 69/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3131 - acc: 0.8816 - val_loss: 0.2499 - val_acc: 0.9082\n","Epoch 70/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.3083 - acc: 0.8862 - val_loss: 0.2536 - val_acc: 0.9082\n","Epoch 71/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3093 - acc: 0.8827 - val_loss: 0.2566 - val_acc: 0.9219\n","Epoch 72/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.3074 - acc: 0.8886 - val_loss: 0.2385 - val_acc: 0.9043\n","Epoch 73/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.2939 - acc: 0.8866 - val_loss: 0.4041 - val_acc: 0.8672\n","Epoch 74/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.3194 - acc: 0.8830 - val_loss: 0.2482 - val_acc: 0.9111\n","Epoch 75/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3067 - acc: 0.8888 - val_loss: 0.2396 - val_acc: 0.9258\n","Epoch 76/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3027 - acc: 0.8905 - val_loss: 0.2259 - val_acc: 0.9160\n","Epoch 77/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3013 - acc: 0.8881 - val_loss: 0.2336 - val_acc: 0.9111\n","Epoch 78/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3039 - acc: 0.8886 - val_loss: 0.2164 - val_acc: 0.9131\n","Epoch 79/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.2997 - acc: 0.8857 - val_loss: 0.2808 - val_acc: 0.8887\n","Epoch 80/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.2902 - acc: 0.8897 - val_loss: 0.3364 - val_acc: 0.9062\n","Epoch 81/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3278 - acc: 0.8819 - val_loss: 0.3294 - val_acc: 0.8838\n","Epoch 82/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.3032 - acc: 0.8849 - val_loss: 0.2405 - val_acc: 0.8945\n","Epoch 83/100\n","71/71 [==============================] - 17s 244ms/step - loss: 0.2943 - acc: 0.8897 - val_loss: 0.2327 - val_acc: 0.9121\n","Epoch 84/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.2895 - acc: 0.8901 - val_loss: 0.2369 - val_acc: 0.9219\n","Epoch 85/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.2980 - acc: 0.8899 - val_loss: 0.2361 - val_acc: 0.9170\n","Epoch 86/100\n","71/71 [==============================] - 18s 248ms/step - loss: 0.3036 - acc: 0.8894 - val_loss: 0.2028 - val_acc: 0.9258\n","Epoch 87/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.2821 - acc: 0.8967 - val_loss: 0.2306 - val_acc: 0.9150\n","Epoch 88/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.2890 - acc: 0.8912 - val_loss: 0.1854 - val_acc: 0.9336\n","Epoch 89/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.2908 - acc: 0.8932 - val_loss: 0.2334 - val_acc: 0.9258\n","Epoch 90/100\n","71/71 [==============================] - 18s 252ms/step - loss: 0.2816 - acc: 0.8947 - val_loss: 0.3275 - val_acc: 0.8955\n","Epoch 91/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.2983 - acc: 0.8915 - val_loss: 0.2317 - val_acc: 0.9004\n","Epoch 92/100\n","71/71 [==============================] - 18s 247ms/step - loss: 0.2818 - acc: 0.8947 - val_loss: 0.2359 - val_acc: 0.9248\n","Epoch 93/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.2893 - acc: 0.8945 - val_loss: 0.2680 - val_acc: 0.8994\n","Epoch 94/100\n","71/71 [==============================] - 18s 251ms/step - loss: 0.2827 - acc: 0.8938 - val_loss: 0.3178 - val_acc: 0.9023\n","Epoch 95/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.3035 - acc: 0.8902 - val_loss: 0.2245 - val_acc: 0.9160\n","Epoch 96/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.2739 - acc: 0.8959 - val_loss: 0.6109 - val_acc: 0.8682\n","Epoch 97/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.2828 - acc: 0.8954 - val_loss: 0.2645 - val_acc: 0.9170\n","Epoch 98/100\n","71/71 [==============================] - 18s 250ms/step - loss: 0.2809 - acc: 0.8999 - val_loss: 0.1776 - val_acc: 0.9375\n","Epoch 99/100\n","71/71 [==============================] - 18s 249ms/step - loss: 0.2780 - acc: 0.8979 - val_loss: 0.1859 - val_acc: 0.9326\n","Epoch 100/100\n","71/71 [==============================] - 17s 246ms/step - loss: 0.2981 - acc: 0.8929 - val_loss: 0.2235 - val_acc: 0.9092\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q3ybW07WYZq3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}